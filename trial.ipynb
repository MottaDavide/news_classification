{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processing import *\n",
    "import numpy as np\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/config.yaml\", 'r') as ymlfile:\n",
    "    config = yaml.safe_load(ymlfile)\n",
    "    \n",
    "LABEL_NAMES = config['LABEL_NAMES']\n",
    "RANDOM_STATE = config['RANDOM_STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] LOADING DATA\n",
      "  Development set: 79,997 samples, 7 features\n",
      "Evaluation data shape: (20000, 6)\n",
      "  Train: 79,997 | Eval: 20,000\n",
      "\n",
      "[2] PREPROCESSING\n",
      "Converting timestamp to datetime...\n",
      "Dropping duplicates based on source, title, article, label keeping the most recent one...\n",
      " 1,368 samples removed\n",
      "Dropping duplicates that have the same source, title, article but different label...\n",
      " 2,971 samples removed\n",
      "Dropping id column...\n",
      "  Preprocessed Data: 75,658 samples, 6 features\n",
      "  Puliti: 75,658\n",
      "\n",
      "[3] FEATURE ENGINEERING\n",
      "\n",
      "  Train: 60,526 | Val: 15,132\n",
      "  TF-IDF: 15000 features\n",
      "  Numerical: 6 features\n",
      "  CatBoost: 21 features\n",
      "  Cyclic timestamp: 7 features\n",
      "  TOTAL: 15034 features\n",
      "\n",
      "[4] LOADING TUNED MODELS AND RESULTS\n",
      "\n",
      "======================================================================\n",
      "FINAL EVALUATION ON VALIDATION SET\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "DETAILED ANALYSIS - LinearSVC\n",
      "======================================================================\n",
      "\n",
      "             GLOBAL METRICS             \n",
      "----------------------------------------\n",
      "Accuracy:                 0.7205\n",
      "Macro F1:                 0.7080\n",
      "Weighted F1:              0.7150\n",
      "\n",
      "                          METRICS PER CLASS                           \n",
      "----------------------------------------------------------------------\n",
      "Classe           Precision     Recall   F1-Score    Support        %\n",
      "----------------------------------------------------------------------\n",
      "International News     0.7526     0.7349     0.7436       4507    29.8%\n",
      "Business            0.7174     0.8083     0.7602       2045    13.5%\n",
      "Technology          0.7987     0.8106     0.8046       2159    14.3%\n",
      "Entertainment       0.6515     0.5190     0.5777       1819    12.0%\n",
      "Sports              0.7915     0.9434     0.8608       1678    11.1%\n",
      "General News        0.6278     0.4991     0.5561       2352    15.5%\n",
      "Health              0.5300     0.8497     0.6528        572     3.8%\n",
      "----------------------------------------------------------------------\n",
      "MACRO AVG           0.6956     0.7378     0.7080\n",
      "\n",
      "            ISSUES ANALYSIS             \n",
      "----------------------------------------\n",
      "⚠️  Classes with F1 < 0.65:\n",
      "   - General News: 0.556\n",
      "   - Entertainment: 0.578\n",
      "\n",
      "======================================================================\n",
      "DETAILED ANALYSIS - LightGBM\n",
      "======================================================================\n",
      "\n",
      "             GLOBAL METRICS             \n",
      "----------------------------------------\n",
      "Accuracy:                 0.7236\n",
      "Macro F1:                 0.7161\n",
      "Weighted F1:              0.7231\n",
      "\n",
      "                          METRICS PER CLASS                           \n",
      "----------------------------------------------------------------------\n",
      "Classe           Precision     Recall   F1-Score    Support        %\n",
      "----------------------------------------------------------------------\n",
      "International News     0.7616     0.7278     0.7443       4507    29.8%\n",
      "Business            0.7726     0.8108     0.7912       2045    13.5%\n",
      "Technology          0.8355     0.8258     0.8307       2159    14.3%\n",
      "Entertainment       0.5936     0.5525     0.5723       1819    12.0%\n",
      "Sports              0.8430     0.8862     0.8640       1678    11.1%\n",
      "General News        0.5499     0.5668     0.5582       2352    15.5%\n",
      "Health              0.6069     0.7045     0.6521        572     3.8%\n",
      "----------------------------------------------------------------------\n",
      "MACRO AVG           0.7090     0.7249     0.7161\n",
      "\n",
      "            ISSUES ANALYSIS             \n",
      "----------------------------------------\n",
      "⚠️  Classes with F1 < 0.65:\n",
      "   - General News: 0.558\n",
      "   - Entertainment: 0.572\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "======================================================================\n",
      "  Saved: model/cm_svc.png\n",
      "  Saved: model/cm_lgbm.png\n",
      "  Saved: model/f1_comparison.png\n",
      "  Saved: model/feat_imp_svc.png\n",
      "  Saved: model/feat_imp_lgbm.png\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Model               Macro F1  Weighted F1     Accuracy\n",
      "-------------------------------------------------------\n",
      "LinearSVC             0.7080       0.7150       0.7205\n",
      "LightGBM              0.7161       0.7231       0.7236\n",
      "\n",
      "✅ BEST MODEL: LightGBM (Macro F1: 0.7161)\n",
      "\n",
      "--- BEST HYPERPARAMETERS ---\n",
      "LinearSVC: {'C': 0.1, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'max_iter': 2000}\n",
      "LightGBM: {'verbose': -1, 'subsample': 0.8, 'random_state': 42, 'num_leaves': 70, 'n_estimators': 300, 'min_child_samples': 20, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 0.7, 'class_weight': 'balanced'}\n",
      "\n",
      "[1] LOADING DATA\n",
      "  Development set: 79,997 samples, 7 features\n",
      "Evaluation data shape: (20000, 6)\n",
      "  Train: 79,997 | Eval: 20,000\n",
      "\n",
      "[2] PREPROCESSING\n",
      "Converting timestamp to datetime...\n",
      "Dropping duplicates based on source, title, article, label keeping the most recent one...\n",
      " 1,368 samples removed\n",
      "Dropping duplicates that have the same source, title, article but different label...\n",
      " 2,971 samples removed\n",
      "Dropping id column...\n",
      "  Preprocessed Data: 75,658 samples, 6 features\n",
      "  Puliti: 75,658\n",
      "\n",
      "[3] FEATURE ENGINEERING\n",
      "  TF-IDF: 15000 features\n",
      "  Numerical: 6 features\n",
      "  CatBoost: 21 features\n",
      "  Cyclic timestamp: 7 features\n",
      "  TOTAL: 15034 features\n",
      "\n",
      "[GENERATING SUBMISSION]\n",
      "  Eval Processed: (20000, 15034)\n",
      "  Using Best Model: LightGBM\n",
      "  Submission: model/submission_tuned.csv\n",
      "\n",
      "======================================================================\n",
      "TUNING COMPLETATO!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "\n",
    "OUTPUT_DIR = Path(\"model/\")\n",
    "print(\"\\n[1] LOADING DATA\")\n",
    "df_train, df_eval = load_file(\"data/development.csv\", \"data/evaluation.csv\",sep=\",\", dtype = {\"id\": str, \"page_rank\": int, \"label\": int})\n",
    "print(f\"  Train: {len(df_train):,} | Eval: {len(df_eval):,}\")\n",
    "\n",
    "# Preprocess\n",
    "print(\"\\n[2] PREPROCESSING\")\n",
    "df_train = preprocessing_data(df_train)\n",
    "print(f\"  Puliti: {len(df_train):,}\")\n",
    "\n",
    "# Features\n",
    "print(\"\\n[3] FEATURE ENGINEERING\")\n",
    "df_train = generate_features(df_train, config=config)\n",
    "df_eval = generate_features(df_eval, config=config)\n",
    "\n",
    "# Split\n",
    "X = df_train.drop(columns=['label'])\n",
    "y = df_train['label']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"\\n  Train: {len(X_train):,} | Val: {len(X_val):,}\")\n",
    "\n",
    "# Pipeline\n",
    "pipe = FullPipeline(config=config)\n",
    "X_train_proc, y_train_proc = pipe.fit_transform(X_train, y_train)\n",
    "X_val_proc = pipe.transform(X_val)\n",
    "feature_names = pipe.feature_names_\n",
    "\n",
    "# TUNING\n",
    "try:\n",
    "    import pickle\n",
    "    print(\"\\n[4] LOADING TUNED MODELS AND RESULTS\")\n",
    "    for model in ['lgbm','svc']:\n",
    "        with open(f\"model/best_model_{model}.pkl\", \"rb\") as f:\n",
    "            if model == 'lgbm':\n",
    "                best_lgbm = pickle.load(f)\n",
    "            else:\n",
    "                best_svc = pickle.load(f)\n",
    "        with open(f\"model/best_params_{model}.pkl\", \"rb\") as f:\n",
    "            if model == 'lgbm':\n",
    "                lgbm_params = pickle.load(f)\n",
    "            else:\n",
    "                svc_params = pickle.load(f)\n",
    "        if model == 'lgbm':\n",
    "            lgbm_results = pd.read_csv(f\"model/lgbm_tuning_results.csv\")\n",
    "        else:\n",
    "            svc_results = pd.read_csv(f\"model/svc_tuning_results.csv\")\n",
    "except:\n",
    "    best_svc, svc_params, svc_results = tune_linear_svc(X_train_proc, y_train_proc, cv=5)\n",
    "    best_lgbm, lgbm_params, lgbm_results = tune_lightgbm(X_train_proc, y_train_proc, cv=5)\n",
    "\n",
    "# EVALUATION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL EVALUATION ON VALIDATION SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {}\n",
    "\n",
    "y_pred_svc = best_svc.predict(X_val_proc)\n",
    "results['LinearSVC'] = detailed_report(y_val.values, y_pred_svc, \"LinearSVC\")\n",
    "\n",
    "y_pred_lgbm = best_lgbm.predict(X_val_proc)\n",
    "results['LightGBM'] = detailed_report(y_val.values, y_pred_lgbm, \"LightGBM\")\n",
    "\n",
    "# VISUALIZATIONS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "plot_confusion_matrix(y_val.values, y_pred_svc, \"LinearSVC\", \n",
    "                        save_path=str(OUTPUT_DIR / \"cm_svc.png\"))\n",
    "plot_confusion_matrix(y_val.values, y_pred_lgbm, \"LightGBM\",\n",
    "                        save_path=str(OUTPUT_DIR / \"cm_lgbm.png\"))\n",
    "plot_f1_comparison(results, save_path=str(OUTPUT_DIR / \"f1_comparison.png\"))\n",
    "plot_feature_importance_svc(best_svc, feature_names, top_n=15,\n",
    "                                save_path=str(OUTPUT_DIR / \"feat_imp_svc.png\"))\n",
    "plot_feature_importance_lgbm(best_lgbm, feature_names, top_n=30,\n",
    "                                save_path=str(OUTPUT_DIR / \"feat_imp_lgbm.png\"))\n",
    "#plot_cv_tuning(svc_results, 'C', 'LinearSVC', save_path=str(OUTPUT_DIR / \"tuning_C.png\"))\n",
    "\n",
    "# SUMMARY\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Model':<15} {'Macro F1':>12} {'Weighted F1':>12} {'Accuracy':>12}\")\n",
    "print(\"-\"*55)\n",
    "for name, m in results.items():\n",
    "    print(f\"{name:<15} {m['macro_f1']:>12.4f} {m['weighted_f1']:>12.4f} {m['accuracy']:>12.4f}\")\n",
    "\n",
    "best_name = max(results, key=lambda x: results[x]['macro_f1'])\n",
    "print(f\"\\n✅ BEST MODEL: {best_name} (Macro F1: {results[best_name]['macro_f1']:.4f})\")\n",
    "\n",
    "print(\"\\n--- BEST HYPERPARAMETERS ---\")\n",
    "print(f\"LinearSVC: {svc_params}\")\n",
    "print(f\"LightGBM: {lgbm_params}\")\n",
    "\n",
    "\n",
    "print(\"\\n[1] LOADING DATA\")\n",
    "df_train, df_eval = load_file(\"data/development.csv\", \"data/evaluation.csv\",sep=\",\", dtype = {\"id\": str, \"page_rank\": int, \"label\": int})\n",
    "print(f\"  Train: {len(df_train):,} | Eval: {len(df_eval):,}\")\n",
    "\n",
    "# Preprocess\n",
    "print(\"\\n[2] PREPROCESSING\")\n",
    "df_train = preprocessing_data(df_train)\n",
    "print(f\"  Puliti: {len(df_train):,}\")\n",
    "\n",
    "# Features\n",
    "print(\"\\n[3] FEATURE ENGINEERING\")\n",
    "df_train = generate_features(df_train, config=config)\n",
    "df_eval = generate_features(df_eval, config=config)\n",
    "\n",
    "X = df_train.drop(columns=['label'])\n",
    "y = df_train['label']\n",
    "\n",
    "pipe_new = FullPipeline(config=config)\n",
    "\n",
    "X_tot, y_tot = pipe_new.fit_transform(X, y)\n",
    "\n",
    "# Submission\n",
    "print(\"\\n[GENERATING SUBMISSION]\")\n",
    "X_eval_proc = pipe_new.transform(df_eval)\n",
    "print(f\"  Eval Processed: {X_eval_proc.shape}\")\n",
    "print(f\"  Using Best Model: {best_name}\")\n",
    "if best_name == 'LinearSVC':\n",
    "    from sklearn.svm import LinearSVC\n",
    "    svc = LinearSVC(**svc_params, random_state=RANDOM_STATE)\n",
    "    svc.fit(X_tot, y_tot)   \n",
    "    y_eval_pred = svc.predict(X_eval_proc)\n",
    "else:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    lgbm = LGBMClassifier(**lgbm_params)\n",
    "    lgbm.fit(X_tot, y_tot)\n",
    "    y_eval_pred = lgbm.predict(X_eval_proc)\n",
    "    \n",
    "    \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': df_eval['Id'],\n",
    "    'Predicted': y_eval_pred.astype(int)\n",
    "})\n",
    "submission.to_csv(OUTPUT_DIR / 'submission_tuned.csv', index=False)\n",
    "print(f\"  Submission: {OUTPUT_DIR / 'submission_tuned.csv'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TUNING COMPLETATO!\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title_suffix</th>\n",
       "      <th>first_link_domain</th>\n",
       "      <th>n_links</th>\n",
       "      <th>n_images</th>\n",
       "      <th>n_ads</th>\n",
       "      <th>n_feeds</th>\n",
       "      <th>article_length</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>Bancrofts to discuss Dow Jones bid with News C...</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://us.rd.yahoo.com/dailynews/r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-06-01 02:29:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us.rd.yahoo.com</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bancrofts to discuss dow jones bid with news c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Pollution turns Yellow River red</td>\n",
       "      <td>A stretch of China's Yellow River runs red for...</td>\n",
       "      <td>5</td>\n",
       "      <td>2006-11-22 14:23:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pollution turns yellow river red pollution tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RedNova</td>\n",
       "      <td>Space Station Not Used Sufficiently, Glenn Says</td>\n",
       "      <td>COLUMBUS, Ohio (AP) -- The country is not gett...</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-02-22 01:54:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>space station not used sufficiently glenn&nbsp;&nbsp;spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Manly men: Crowe, bodyguard hug, make up</td>\n",
       "      <td>Russell Crowe is taking the blame for a fight ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-08-31 19:00:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>manly men crowe bodyguard hug make up manly me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>Microsoft Looks to Expand Windows at Home (AP)</td>\n",
       "      <td>AP - Efforts by Microsoft Corp. and the PC ind...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>microsoft looks to expand windows at home ap m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75653</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>BMW's 2nd-quarter net profit up \\\\n&nbsp;&nbsp;&nbsp;&nbsp;(AP)\\\\n</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://us.rd.yahoo.com/dailynews/r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2006-08-02 16:32:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us.rd.yahoo.com</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bmw s 2nd quarter net profit up ap bmw s 2nd q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75654</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>Missing Ga. hiker believed dead \\\\n&nbsp;&nbsp;&nbsp;&nbsp;(AP)\\\\n</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://us.rd.yahoo.com/dailynews/r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2008-01-06 03:12:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us.rd.yahoo.com</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing ga hiker believed dead ap missing ga h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75655</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>George Michael Hits Back in War of Words with ...</td>\n",
       "      <td>Reuters - Singer George Michael has issued a\\\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>george michael hits back in war of words with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75656</th>\n",
       "      <td>BBC</td>\n",
       "      <td>MI6 'Diana-style' plot dismissed</td>\n",
       "      <td>An ex-MI6 man who told Mohammed Al Fayed of pl...</td>\n",
       "      <td>5</td>\n",
       "      <td>2008-02-13 19:54:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mi6 diana style plot dismissed mi6 diana style...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75657</th>\n",
       "      <td>CNET</td>\n",
       "      <td>Spaceflight to cost $40 million in 2009</td>\n",
       "      <td>Blog: Space Adventures says that the cost of a...</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-20 02:52:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spaceflight to cost&nbsp;&nbsp;million in&nbsp;&nbsp;spaceflight t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75658 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                                              title  \\\n",
       "0        Yahoo  Bancrofts to discuss Dow Jones bid with News C...   \n",
       "1          BBC                   Pollution turns Yellow River red   \n",
       "2      RedNova    Space Station Not Used Sufficiently, Glenn Says   \n",
       "3      Arizona           Manly men: Crowe, bodyguard hug, make up   \n",
       "4        Yahoo     Microsoft Looks to Expand Windows at Home (AP)   \n",
       "...        ...                                                ...   \n",
       "75653    Yahoo     BMW's 2nd-quarter net profit up \\\\n    (AP)\\\\n   \n",
       "75654    Yahoo     Missing Ga. hiker believed dead \\\\n    (AP)\\\\n   \n",
       "75655    Yahoo  George Michael Hits Back in War of Words with ...   \n",
       "75656      BBC                   MI6 'Diana-style' plot dismissed   \n",
       "75657     CNET            Spaceflight to cost $40 million in 2009   \n",
       "\n",
       "                                                 article  page_rank  \\\n",
       "0      <p><a href=\"http://us.rd.yahoo.com/dailynews/r...          5   \n",
       "1      A stretch of China's Yellow River runs red for...          5   \n",
       "2      COLUMBUS, Ohio (AP) -- The country is not gett...          3   \n",
       "3      Russell Crowe is taking the blame for a fight ...          5   \n",
       "4      AP - Efforts by Microsoft Corp. and the PC ind...          5   \n",
       "...                                                  ...        ...   \n",
       "75653  <p><a href=\"http://us.rd.yahoo.com/dailynews/r...          5   \n",
       "75654  <p><a href=\"http://us.rd.yahoo.com/dailynews/r...          5   \n",
       "75655  Reuters - Singer George Michael has issued a\\\\...          5   \n",
       "75656  An ex-MI6 man who told Mohammed Al Fayed of pl...          5   \n",
       "75657  Blog: Space Adventures says that the cost of a...          3   \n",
       "\n",
       "                timestamp title_suffix first_link_domain  n_links  n_images  \\\n",
       "0     2007-06-01 02:29:04          NaN   us.rd.yahoo.com        2         1   \n",
       "1     2006-11-22 14:23:53          NaN               NaN        0         0   \n",
       "2     2007-02-22 01:54:25          NaN               NaN        0         0   \n",
       "3     2004-08-31 19:00:43          NaN               NaN        0         0   \n",
       "4                     NaT           AP               NaN        0         0   \n",
       "...                   ...          ...               ...      ...       ...   \n",
       "75653 2006-08-02 16:32:20          NaN   us.rd.yahoo.com        2         1   \n",
       "75654 2008-01-06 03:12:45          NaN   us.rd.yahoo.com        2         1   \n",
       "75655                 NaT      Reuters               NaN        0         0   \n",
       "75656 2008-02-13 19:54:06          NaN               NaN        0         0   \n",
       "75657 2007-07-20 02:52:24          NaN               NaN        0         0   \n",
       "\n",
       "       n_ads  n_feeds  article_length  \\\n",
       "0          0        0             1.0   \n",
       "1          0        0             1.0   \n",
       "2          0        0             1.0   \n",
       "3          0        0             1.0   \n",
       "4          0        0             1.0   \n",
       "...      ...      ...             ...   \n",
       "75653      0        0             1.0   \n",
       "75654      0        0             1.0   \n",
       "75655      0        0             1.0   \n",
       "75656      0        0             1.0   \n",
       "75657      0        0             1.0   \n",
       "\n",
       "                                           combined_text  \n",
       "0      bancrofts to discuss dow jones bid with news c...  \n",
       "1      pollution turns yellow river red pollution tur...  \n",
       "2      space station not used sufficiently glenn  spa...  \n",
       "3      manly men crowe bodyguard hug make up manly me...  \n",
       "4      microsoft looks to expand windows at home ap m...  \n",
       "...                                                  ...  \n",
       "75653  bmw s 2nd quarter net profit up ap bmw s 2nd q...  \n",
       "75654  missing ga hiker believed dead ap missing ga h...  \n",
       "75655  george michael hits back in war of words with ...  \n",
       "75656  mi6 diana style plot dismissed mi6 diana style...  \n",
       "75657  spaceflight to cost  million in  spaceflight t...  \n",
       "\n",
       "[75658 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           28\n",
       "Predicted     4\n",
       "Name: 28, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.iloc[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for model in ['lgbm','svc']:\n",
    "    with open(f'model/best_model_{model}.pkl', 'wb') as f:\n",
    "        if model=='lgbm':\n",
    "            pickle.dump(best_lgbm, f)\n",
    "        else:\n",
    "            pickle.dump(best_svc, f)\n",
    "    with open(f'model/best_params_{model}.pkl', 'wb') as f:\n",
    "        if model=='lgbm':\n",
    "            pickle.dump(lgbm_params, f)\n",
    "        else:\n",
    "            pickle.dump(svc_params, f)\n",
    "    \n",
    "    if model == 'lgbm':\n",
    "        lgbm_results.to_csv(f'model/lgbm_tuning_results.csv', index=False)\n",
    "    else:\n",
    "        svc_results.to_csv(f'model/svc_tuning_results.csv', index=False)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': -1,\n",
       " 'subsample': 0.8,\n",
       " 'random_state': 42,\n",
       " 'num_leaves': 70,\n",
       " 'n_estimators': 300,\n",
       " 'min_child_samples': 20,\n",
       " 'max_depth': -1,\n",
       " 'learning_rate': 0.1,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.808015</td>\n",
       "      <td>1.648096</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>0.705411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701534</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782346</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.783877</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.781580</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.589021</td>\n",
       "      <td>0.673211</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.05</td>\n",
       "      <td>balanced</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.05, 'class_weight': 'balanced', 'loss'...</td>\n",
       "      <td>0.699209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697552</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.754766</td>\n",
       "      <td>0.756628</td>\n",
       "      <td>0.756354</td>\n",
       "      <td>0.754816</td>\n",
       "      <td>0.755606</td>\n",
       "      <td>0.000768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.722066</td>\n",
       "      <td>2.048436</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.50</td>\n",
       "      <td>balanced</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.5, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>0.698107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692018</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>3</td>\n",
       "      <td>0.854954</td>\n",
       "      <td>0.856083</td>\n",
       "      <td>0.857310</td>\n",
       "      <td>0.857909</td>\n",
       "      <td>0.857273</td>\n",
       "      <td>0.856706</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.177038</td>\n",
       "      <td>4.152274</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>1.00</td>\n",
       "      <td>balanced</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>0.685705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679576</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>0.889561</td>\n",
       "      <td>0.889471</td>\n",
       "      <td>0.889816</td>\n",
       "      <td>0.890082</td>\n",
       "      <td>0.889306</td>\n",
       "      <td>0.000879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.428463</td>\n",
       "      <td>0.770374</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'loss'...</td>\n",
       "      <td>0.667689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>5</td>\n",
       "      <td>0.691349</td>\n",
       "      <td>0.689833</td>\n",
       "      <td>0.688710</td>\n",
       "      <td>0.691444</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.690149</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.898593</td>\n",
       "      <td>4.303390</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>balanced</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 2.0, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>0.668627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665022</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>6</td>\n",
       "      <td>0.918240</td>\n",
       "      <td>0.920269</td>\n",
       "      <td>0.920916</td>\n",
       "      <td>0.920634</td>\n",
       "      <td>0.920450</td>\n",
       "      <td>0.920102</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.258786</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'loss'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.044191</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.05, 'class_weight': 'balanced', 'loss'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 0.5, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024570</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'C': 2.0, 'class_weight': 'balanced', 'loss':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0       41.808015      1.648096         0.017114        0.005129     0.10   \n",
       "1       39.589021      0.673211         0.026485        0.018371     0.05   \n",
       "2       48.722066      2.048436         0.016326        0.005676     0.50   \n",
       "3       52.177038      4.152274         0.018768        0.007443     1.00   \n",
       "4       25.428463      0.770374         0.021528        0.004896     0.01   \n",
       "5       50.898593      4.303390         0.011583        0.000667     2.00   \n",
       "6        0.258786      0.006921         0.000000        0.000000     0.01   \n",
       "7        0.044191      0.005870         0.000000        0.000000     0.05   \n",
       "8        0.033654      0.006759         0.000000        0.000000     0.10   \n",
       "9        0.027746      0.007649         0.000000        0.000000     0.50   \n",
       "10       0.024206      0.003916         0.000000        0.000000     1.00   \n",
       "11       0.024570      0.004834         0.000000        0.000000     2.00   \n",
       "\n",
       "   param_class_weight     param_loss  param_max_iter  \\\n",
       "0            balanced  squared_hinge            2000   \n",
       "1            balanced  squared_hinge            2000   \n",
       "2            balanced  squared_hinge            2000   \n",
       "3            balanced  squared_hinge            2000   \n",
       "4            balanced  squared_hinge            2000   \n",
       "5            balanced  squared_hinge            2000   \n",
       "6            balanced          hinge            2000   \n",
       "7            balanced          hinge            2000   \n",
       "8            balanced          hinge            2000   \n",
       "9            balanced          hinge            2000   \n",
       "10           balanced          hinge            2000   \n",
       "11           balanced          hinge            2000   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "0   {'C': 0.1, 'class_weight': 'balanced', 'loss':...           0.705411  ...   \n",
       "1   {'C': 0.05, 'class_weight': 'balanced', 'loss'...           0.699209  ...   \n",
       "2   {'C': 0.5, 'class_weight': 'balanced', 'loss':...           0.698107  ...   \n",
       "3   {'C': 1.0, 'class_weight': 'balanced', 'loss':...           0.685705  ...   \n",
       "4   {'C': 0.01, 'class_weight': 'balanced', 'loss'...           0.667689  ...   \n",
       "5   {'C': 2.0, 'class_weight': 'balanced', 'loss':...           0.668627  ...   \n",
       "6   {'C': 0.01, 'class_weight': 'balanced', 'loss'...                NaN  ...   \n",
       "7   {'C': 0.05, 'class_weight': 'balanced', 'loss'...                NaN  ...   \n",
       "8   {'C': 0.1, 'class_weight': 'balanced', 'loss':...                NaN  ...   \n",
       "9   {'C': 0.5, 'class_weight': 'balanced', 'loss':...                NaN  ...   \n",
       "10  {'C': 1.0, 'class_weight': 'balanced', 'loss':...                NaN  ...   \n",
       "11  {'C': 2.0, 'class_weight': 'balanced', 'loss':...                NaN  ...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.701534        0.002141                1            0.782346   \n",
       "1          0.697552        0.001265                2            0.755464   \n",
       "2          0.692018        0.003184                3            0.854954   \n",
       "3          0.679576        0.003470                4            0.887600   \n",
       "4          0.665714        0.002689                5            0.691349   \n",
       "5          0.665022        0.002547                6            0.918240   \n",
       "6               NaN             NaN                7                 NaN   \n",
       "7               NaN             NaN                7                 NaN   \n",
       "8               NaN             NaN                7                 NaN   \n",
       "9               NaN             NaN                7                 NaN   \n",
       "10              NaN             NaN                7                 NaN   \n",
       "11              NaN             NaN                7                 NaN   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0             0.781826            0.783877            0.783951   \n",
       "1             0.754766            0.756628            0.756354   \n",
       "2             0.856083            0.857310            0.857909   \n",
       "3             0.889561            0.889471            0.889816   \n",
       "4             0.689833            0.688710            0.691444   \n",
       "5             0.920269            0.920916            0.920634   \n",
       "6                  NaN                 NaN                 NaN   \n",
       "7                  NaN                 NaN                 NaN   \n",
       "8                  NaN                 NaN                 NaN   \n",
       "9                  NaN                 NaN                 NaN   \n",
       "10                 NaN                 NaN                 NaN   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.781580          0.782716         0.001009  \n",
       "1             0.754816          0.755606         0.000768  \n",
       "2             0.857273          0.856706         0.001057  \n",
       "3             0.890082          0.889306         0.000879  \n",
       "4             0.689408          0.690149         0.001080  \n",
       "5             0.920450          0.920102         0.000955  \n",
       "6                  NaN               NaN              NaN  \n",
       "7                  NaN               NaN              NaN  \n",
       "8                  NaN               NaN              NaN  \n",
       "9                  NaN               NaN              NaN  \n",
       "10                 NaN               NaN              NaN  \n",
       "11                 NaN               NaN              NaN  \n",
       "\n",
       "[12 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbest_svc\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m(OUTPUT_DIR / \u001b[33m\"\u001b[39m\u001b[33mbest_svc_model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m svc_params\n\u001b[32m      3\u001b[39m svc_results\n",
      "\u001b[31mAttributeError\u001b[39m: 'LinearSVC' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "best_svc.save(OUTPUT_DIR / \"best_svc_model.pkl\")\n",
    "svc_params\n",
    "svc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('model/best_svc_model.pkl','wb') as f:\n",
    "    pickle.dump(best_svc,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('model/best_lgbm_model.pkl','wb') as f:\n",
    "    pickle.dump(best_lgbm,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.7, n_estimators=300,\n",
       "               n_jobs=-1, num_leaves=70, objective=&#x27;multiclass&#x27;,\n",
       "               random_state=42, subsample=0.8, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves</td>\n",
       "            <td class=\"value\">70</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective</td>\n",
       "            <td class=\"value\">&#x27;multiclass&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree</td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', colsample_bytree=0.7, n_estimators=300,\n",
       "               n_jobs=-1, num_leaves=70, objective='multiclass',\n",
       "               random_state=42, subsample=0.8, verbose=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Development set: 79,997 samples, 7 features\n"
     ]
    }
   ],
   "source": [
    "dev_df, _ = load_file(\"data/development.csv\", sep=\",\", dtype = {\"id\": str, \"page_rank\": int, \"label\": int})\n",
    "dev_df_original = dev_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting timestamp to datetime...\n",
      "Dropping duplicates based on source, title, article, label keeping the most recent one...\n",
      " 1,368 samples removed\n",
      "Dropping duplicates that have the same source, title, article but different label...\n",
      " 2,971 samples removed\n",
      "Dropping id column...\n",
      "  Preprocessed Data: 75,658 samples, 6 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_clean = preprocessing_data(dev_df_original)\n",
    "\n",
    "df_clean = generate_features(df_clean, config=config)\n",
    "\n",
    "X = df_clean.drop('label', axis=1)\n",
    "y = df_clean['label']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = FullPipeline(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'ngram_range' parameter of TfidfVectorizer must be an instance of 'tuple'. Got '(1, 2)' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-LuxotticaGroupS.p.A/Desktop/news_classification /ds_venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-LuxotticaGroupS.p.A/Desktop/news_classification /utils/processing.py:340\u001b[39m, in \u001b[36mFullPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mTFIDF\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mENABLE\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28mself\u001b[39m.tfidf = TfidfVectorizer(**\u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mTFIDF\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mPARAMS\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     X_tfidf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtfidf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcombined_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m     features_list.append(X_tfidf)\n\u001b[32m    342\u001b[39m     feature_names.extend([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtfidf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tfidf.get_feature_names_out()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-LuxotticaGroupS.p.A/Desktop/news_classification /ds_venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:2104\u001b[39m, in \u001b[36mTfidfVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._check_params()\n\u001b[32m   2098\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf = TfidfTransformer(\n\u001b[32m   2099\u001b[39m     norm=\u001b[38;5;28mself\u001b[39m.norm,\n\u001b[32m   2100\u001b[39m     use_idf=\u001b[38;5;28mself\u001b[39m.use_idf,\n\u001b[32m   2101\u001b[39m     smooth_idf=\u001b[38;5;28mself\u001b[39m.smooth_idf,\n\u001b[32m   2102\u001b[39m     sublinear_tf=\u001b[38;5;28mself\u001b[39m.sublinear_tf,\n\u001b[32m   2103\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2104\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2105\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf.fit(X)\n\u001b[32m   2106\u001b[39m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[32m   2107\u001b[39m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-LuxotticaGroupS.p.A/Desktop/news_classification /ds_venv/lib/python3.11/site-packages/sklearn/base.py:1329\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1324\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1325\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1326\u001b[39m )\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-LuxotticaGroupS.p.A/Desktop/news_classification /ds_venv/lib/python3.11/site-packages/sklearn/base.py:492\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    485\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    486\u001b[39m \n\u001b[32m    487\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-LuxotticaGroupS.p.A/Desktop/news_classification /ds_venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'ngram_range' parameter of TfidfVectorizer must be an instance of 'tuple'. Got '(1, 2)' instead."
     ]
    }
   ],
   "source": [
    "pipe.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_args = {\n",
    "    'max_features': 10000,\n",
    "    'ngram_range': (1, 2),\n",
    "    'min_df': 5,\n",
    "    'max_df': 0.8,\n",
    "    'token_pattern': r'(?u)\\b[a-zA-Z]{3,}\\b',\n",
    "    'stop_words': 'english',\n",
    "    'sublinear_tf': True\n",
    "}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "preproc_pipe = pipeline(tfidf_args)\n",
    "\n",
    "preproc_pipe.fit_transform(X_train, y_train)\n",
    "feature_names = preproc_pipe.named_steps['processor'].get_feature_names_out()\n",
    "\n",
    "X_train_processed = preproc_pipe.fit_transform(X_train, y_train)\n",
    "\n",
    "\n",
    "X_val_processed = preproc_pipe.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression...... CV: 0.6429 | Test: 0.6647\n",
      "Linear SVM............... CV: 0.6965 | Test: 0.7054\n",
      "Random Forest............ CV: 0.6612 | Test: 0.6743\n",
      "XGBoost.................. CV: 0.6844 | Test: 0.6951\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.975764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231520\n",
      "[LightGBM] [Info] Number of data points in the train set: 40350, number of used features: 7412\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.511181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 232522\n",
      "[LightGBM] [Info] Number of data points in the train set: 40351, number of used features: 7392\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.506534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 232292\n",
      "[LightGBM] [Info] Number of data points in the train set: 40351, number of used features: 7400\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.796914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342642\n",
      "[LightGBM] [Info] Number of data points in the train set: 60526, number of used features: 9258\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "[LightGBM] [Info] Start training from score -1.945910\n",
      "LightGBM................. CV: 0.6965 | Test: 0.7024\n",
      "\n",
      "==================== LOGISTIC REGRESSION ====================\n",
      "Classe International News: source_prob_cl_0, afp, iraq, president, title_suffix_prob_cl_0, minister, police, page_rank, leader, election\n",
      "Classe Business: source_prob_cl_1, company, profit, oil, first_link_domain_prob_cl_1, billion, sales, shares, percent, stocks\n",
      "Classe Technology: source_prob_cl_2, microsoft, internet, space, title_suffix_prob_cl_2, first_link_domain_prob_cl_2, online, com, web, software\n",
      "Classe Entertainment: source_prob_cl_3, film, movie, hollywood, music, star, actor, singer, actress, review\n",
      "Classe Sports: source_prob_cl_4, team, game, season, win, victory, coach, night, cup, league\n",
      "Classe General News: source_prob_cl_5, first_link_domain_prob_cl_5, iraq, title_suffix_prob_cl_5, bush, baghdad, president, police, n_feeds, page_rank\n",
      "Classe Health: health, cancer, study, drug, flu, researchers, aids, disease, children, vaccine\n",
      "\n",
      "==================== LINEAR SVM ====================\n",
      "Classe International News: afp, source_prob_cl_0, afp afp, president, political, poland, diplomats, leader, russia, democratic\n",
      "Classe Business: reuters reuters, reuters oil, economy, retailer, source_prob_cl_1, mortgage, boeing, bank, profit, regulators\n",
      "Classe Technology: internet, world world, infoworld, species, software, digital, space, nasa, online, science\n",
      "Classe Entertainment: actor, actress, singer, movie, music, film, online online, album, hollywood, documentary\n",
      "Classe Sports: team, coach, mets, bowl, players, player, quarterback, patriots, basketball, points\n",
      "Classe General News: baghdad reuters, source_prob_cl_5, adv, reuters president, first_link_domain_prob_cl_5, life style, business money, washington reuters, arts entertainment, title_suffix_prob_cl_5\n",
      "Classe Health: health, cancer, aids, researchers, drug, medical, flu, healthday, study, disease\n",
      "\n",
      "==================== RANDOM FOREST ====================\n",
      "Top Feature Globali: source_prob_cl_2, source_prob_cl_4, source_prob_cl_1, source_prob_cl_5, source_prob_cl_0, source_prob_cl_3, source_prob_cl_6, page_rank, first_link_domain_prob_cl_5, first_link_domain_prob_cl_2\n",
      "\n",
      "==================== XGBOOST ====================\n",
      "Top Feature Globali: hollywood reporter, scored, sports network, york, profit, source_prob_cl_2, wall street, health, victory, points\n",
      "\n",
      "==================== LIGHTGBM ====================\n",
      "Top Feature Globali: source_prob_cl_2, source_prob_cl_5, source_prob_cl_1, source_prob_cl_0, source_prob_cl_4, health, page_rank, source_prob_cl_3, study, drug\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Calcolo dei pesi per Naive Bayes (per gestire lo sbilanciamento)\n",
    "weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "priors = weights / weights.sum()\n",
    "\n",
    "# Modelli aggiornati\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000, C = 0.05, random_state=42),\n",
    "    \"Linear SVM\": LinearSVC(class_weight='balanced', max_iter=2000, dual=False, C = 0.1, random_state=42),\n",
    "   # \"Multinomial NB\": MultinomialNB(class_prior=priors),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "models[\"LightGBM\"] = LGBMClassifier(\n",
    "    class_weight='balanced', \n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    importance_type='gain' # 'gain' è meglio di 'split' per capire l'impatto reale\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    full_pipe = Pipeline([\n",
    "        ('preprocessor', preproc_pipe),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Cross-Validation\n",
    "    cv_f1 = cross_val_score(full_pipe, X_train, y_train, cv=3, scoring='f1_macro').mean()\n",
    "    \n",
    "    # Training finale\n",
    "    full_pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = full_pipe.predict(X_val)\n",
    "    test_f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    results[name] = {\"cv_f1\": cv_f1, \"test_f1\": test_f1, \"pipe\": full_pipe}\n",
    "    print(f\"{name:.<25} CV: {cv_f1:.4f} | Test: {test_f1:.4f}\")\n",
    "    \n",
    "    \n",
    "def get_top_features_summary(results, top_n=10):\n",
    "    # Recuperiamo i nomi dal preprocessor della Logistic Regression (o qualsiasi altro)\n",
    "    feature_names = results[\"Logistic Regression\"][\"pipe\"].named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    for name, data in results.items():\n",
    "        print(f\"\\n{'='*20} {name.upper()} {'='*20}\")\n",
    "        clf = data[\"pipe\"].named_steps['classifier']\n",
    "        \n",
    "        # CASO 1: Modelli Lineari e NB (Coefficienti per classe)\n",
    "        if hasattr(clf, 'coef_') or hasattr(clf, 'feature_log_prob_'):\n",
    "            weights = clf.feature_log_prob_ if name == \"Multinomial NB\" else clf.coef_\n",
    "            \n",
    "            # Se il modello è binario, coef_ ha una sola riga, se multiclasse ne ha N\n",
    "            n_classes = weights.shape[0] if len(weights.shape) > 1 else 1\n",
    "            \n",
    "            for i in range(n_classes):\n",
    "                w = weights[i] if n_classes > 1 else weights\n",
    "                top_indices = np.argsort(w)[-top_n:]\n",
    "                top_words = [feature_names[idx].split(\"__\")[-1] for idx in top_indices]\n",
    "                label = LABEL_NAMES[i] if i < len(LABEL_NAMES) else i\n",
    "                print(f\"Classe {label}: {', '.join(top_words[::-1])}\")\n",
    "        \n",
    "        # CASO 2: Modelli ad Albero (Importanza Globale: RF, XGBoost, LightGBM)\n",
    "        elif hasattr(clf, 'feature_importances_'):\n",
    "            importances = clf.feature_importances_\n",
    "            top_indices = np.argsort(importances)[-top_n:]\n",
    "            # Puliamo i nomi rimuovendo i prefissi della pipeline per leggibilità\n",
    "            top_features = [feature_names[idx].split(\"__\")[-1] for idx in top_indices]\n",
    "            print(f\"Top Feature Globali: {', '.join(top_features[::-1])}\")\n",
    "\n",
    "# Eseguiamo il riepilogo\n",
    "get_top_features_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69842</th>\n",
       "      <td>CNET</td>\n",
       "      <td>Everex hits the books with $298 open-source de...</td>\n",
       "      <td>Blog: Everex announces Wal-Mart will carry its...</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-19 21:50:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52331</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Pakistan buries Red Mosque dead</td>\n",
       "      <td>The bodies of dozens of people killed after Pa...</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-07-12 14:18:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>Slashdot</td>\n",
       "      <td>Mozilla Thunderbird Reaches 1.0</td>\n",
       "      <td>An anonymous reader writes &amp;quot;Mozilla Thund...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>Sudan promises to let sick Darfur rebel travel...</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://us.rd.yahoo.com/dailynews/r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-09-04 09:48:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>Radio</td>\n",
       "      <td>Russian Tax Authorities Give Yukos Another, La...</td>\n",
       "      <td>3 September 2004 -- Russia&amp;#39;s tax authoriti...</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-09-08 09:37:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64737</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>Alstom wins 130 million Euro contract for subw...</td>\n",
       "      <td>AFP - French industrial giant Alstom Group has...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66409</th>\n",
       "      <td>New</td>\n",
       "      <td>City Room: Baseball Officials Miss Gang Hearing</td>\n",
       "      <td>Neither Major League Baseball nor its official...</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-12-14 00:03:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26111</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>Swedes beam poetry into outer space (Reuters)</td>\n",
       "      <td>Reuters - Swedish poets have broadcast their w...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13549</th>\n",
       "      <td>Voice</td>\n",
       "      <td>Powell Cancels Athens Trip</td>\n",
       "      <td>The US State Department says Secretary Colin P...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24444</th>\n",
       "      <td>RedNova</td>\n",
       "      <td>REPORT: Super Bowl Web Site Compromised With M...</td>\n",
       "      <td>SAN DIEGO, Feb. 2&nbsp;&nbsp;/PRNewswire-FirstCall/ -- W...</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-02-03 00:17:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60526 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                                              title  \\\n",
       "69842      CNET  Everex hits the books with $298 open-source de...   \n",
       "52331       BBC                    Pakistan buries Red Mosque dead   \n",
       "11157  Slashdot                    Mozilla Thunderbird Reaches 1.0   \n",
       "8112      Yahoo  Sudan promises to let sick Darfur rebel travel...   \n",
       "29337     Radio  Russian Tax Authorities Give Yukos Another, La...   \n",
       "...         ...                                                ...   \n",
       "64737     Yahoo  Alstom wins 130 million Euro contract for subw...   \n",
       "66409       New    City Room: Baseball Officials Miss Gang Hearing   \n",
       "26111     Yahoo      Swedes beam poetry into outer space (Reuters)   \n",
       "13549     Voice                         Powell Cancels Athens Trip   \n",
       "24444   RedNova  REPORT: Super Bowl Web Site Compromised With M...   \n",
       "\n",
       "                                                 article  page_rank  \\\n",
       "69842  Blog: Everex announces Wal-Mart will carry its...          3   \n",
       "52331  The bodies of dozens of people killed after Pa...          5   \n",
       "11157  An anonymous reader writes &quot;Mozilla Thund...          5   \n",
       "8112   <p><a href=\"http://us.rd.yahoo.com/dailynews/r...          5   \n",
       "29337  3 September 2004 -- Russia&#39;s tax authoriti...          5   \n",
       "...                                                  ...        ...   \n",
       "64737  AFP - French industrial giant Alstom Group has...          5   \n",
       "66409  Neither Major League Baseball nor its official...          5   \n",
       "26111  Reuters - Swedish poets have broadcast their w...          5   \n",
       "13549  The US State Department says Secretary Colin P...          5   \n",
       "24444  SAN DIEGO, Feb. 2  /PRNewswire-FirstCall/ -- W...          4   \n",
       "\n",
       "                timestamp  \n",
       "69842 2007-07-19 21:50:09  \n",
       "52331 2007-07-12 14:18:01  \n",
       "11157                 NaT  \n",
       "8112  2007-09-04 09:48:01  \n",
       "29337 2004-09-08 09:37:18  \n",
       "...                   ...  \n",
       "64737                 NaT  \n",
       "66409 2007-12-14 00:03:06  \n",
       "26111                 NaT  \n",
       "13549                 NaT  \n",
       "24444 2007-02-03 00:17:27  \n",
       "\n",
       "[60526 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df_melt = results_df.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
    "    sns.barplot(data=df_melt, x=\"Model\", y=\"Score\", hue=\"Metric\", palette=\"viridis\")\n",
    "    plt.title(\"Comparazione Modelli - Macro F1 Score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def show_top_words(trained_pipelines, label_names, top_n=10):\n",
    "    # Recuperiamo i nomi delle feature dall'ultimo modello addestrato\n",
    "    any_pipe = list(trained_pipelines.values())[0]\n",
    "    feat_names = any_pipe.named_steps['proc'].get_feature_names_out()\n",
    "\n",
    "    for name, pipe in trained_pipelines.items():\n",
    "        clf = pipe.named_steps['model']\n",
    "        print(f\"\\n--- Top Words per Classe ({name}) ---\")\n",
    "        \n",
    "        if hasattr(clf, 'coef_') or hasattr(clf, 'feature_log_prob_'):\n",
    "            weights = clf.feature_log_prob_ if name == \"Naive Bayes\" else clf.coef_\n",
    "            for i, label in enumerate(label_names):\n",
    "                top_ids = np.argsort(weights[i])[-top_n:]\n",
    "                words = [feat_names[idx].split('__')[-1] for idx in top_ids] # Pulizia prefissi\n",
    "                print(f\"{label}: {', '.join(words[::-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'melt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m(results_df)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_results\u001b[39m(results_df):\n\u001b[32m      2\u001b[39m     plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df_melt = \u001b[43mresults_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmelt\u001b[49m(id_vars=\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m, var_name=\u001b[33m\"\u001b[39m\u001b[33mMetric\u001b[39m\u001b[33m\"\u001b[39m, value_name=\u001b[33m\"\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     sns.barplot(data=df_melt, x=\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m, y=\u001b[33m\"\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m\"\u001b[39m, hue=\u001b[33m\"\u001b[39m\u001b[33mMetric\u001b[39m\u001b[33m\"\u001b[39m, palette=\u001b[33m\"\u001b[39m\u001b[33mviridis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     plt.title(\u001b[33m\"\u001b[39m\u001b[33mComparazione Modelli - Macro F1 Score\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'melt'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
